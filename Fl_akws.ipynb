{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import glob\n",
    "\n",
    "\n",
    "os.makedirs('spectrograms/bed', exist_ok=True)\n",
    "os.makedirs('spectrograms/happy', exist_ok=True)\n",
    "\n",
    "\n",
    "audio_dir = \"/audio\" \n",
    "\n",
    "\n",
    "bed_files = glob.glob(os.path.join(audio_dir, 'bed/*.wav'))\n",
    "happy_files = glob.glob(os.path.join(audio_dir, 'happy/*.wav'))\n",
    "\n",
    "\n",
    "print(\"Bed files:\", bed_files)\n",
    "print(\"Happy files:\", happy_files)\n",
    "\n",
    "def create_spectrogram(audio_file, label, index):\n",
    "    \n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    \n",
    "   \n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)  # Updated this line\n",
    "    \n",
    "    \n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mel_spectrogram_db, sr=sr, x_axis='time', y_axis='mel', fmax=8000)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f'Mel Spectrogram - {label}')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    filename = os.path.join('spectrograms', label, f'{index}_{label}_spectrogram.png')\n",
    "    plt.savefig(filename)\n",
    "    plt.close()  \n",
    "\n",
    "\n",
    "for idx, audio_file in enumerate(bed_files):\n",
    "    create_spectrogram(audio_file, 'bed', idx + 1)\n",
    "\n",
    "\n",
    "for idx, audio_file in enumerate(happy_files):\n",
    "    create_spectrogram(audio_file, 'happy', idx + 1)\n",
    "\n",
    "print(\"Spectrograms generated and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import glob\n",
    "\n",
    "\n",
    "spectrogram_dir = 'spectrograms/'  \n",
    "\n",
    "\n",
    "def load_data(spectrogram_dir):\n",
    "    X = []  \n",
    "    y = []  \n",
    "\n",
    "    \n",
    "    bed_images = glob.glob(os.path.join(spectrogram_dir, 'bed/*.png'))\n",
    "    for img_path in bed_images:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (128, 128)) \n",
    "        X.append(img)\n",
    "        y.append(0)  \n",
    "\n",
    " \n",
    "    happy_images = glob.glob(os.path.join(spectrogram_dir, 'happy/*.png'))\n",
    "    for img_path in happy_images:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        X.append(img)\n",
    "        y.append(1)  \n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "X, y = load_data(spectrogram_dir)\n",
    "\n",
    "# Normalize the images to [0, 1]\n",
    "X = X.astype('float32') / 255.0  \n",
    "\n",
    "print(\"Loaded data shapes:\", X.shape, y.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Testing labels shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = to_categorical(y_train, num_classes=2)  # Assuming 2 classes: bed and happy\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# Define the base network to be shared\n",
    "def create_base_network(input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the base network\n",
    "input_shape = (128, 128, 3) \n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "# Define the input layers for the two images\n",
    "input_a = layers.Input(shape=input_shape)\n",
    "input_b = layers.Input(shape=input_shape)\n",
    "\n",
    "\n",
    "encoded_a = base_network(input_a)\n",
    "encoded_b = base_network(input_b)\n",
    "\n",
    "\n",
    "merged = layers.Subtract()([encoded_a, encoded_b])\n",
    "output = layers.Dense(1, activation='sigmoid')(merged)  \n",
    "\n",
    "\n",
    "siamese_model = Model(inputs=[input_a, input_b], outputs=output)\n",
    "\n",
    "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "siamese_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(X, y):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    # Create positive pairs\n",
    "    unique_classes = np.unique(y)\n",
    "    for cls in unique_classes:\n",
    "        class_indices = np.where(y == cls)[0]\n",
    "        for i in range(len(class_indices)):\n",
    "            for j in range(i + 1, len(class_indices)):\n",
    "                pairs.append([X[class_indices[i]], X[class_indices[j]]])\n",
    "                labels.append(1)  # Positive pair\n",
    "\n",
    "    # Create negative pairs\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X)):\n",
    "            if y[i] != y[j]:\n",
    "                pairs.append([X[i], X[j]])\n",
    "                labels.append(0)  # Negative pair\n",
    "\n",
    "    return np.array(pairs), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X and y are your image data and labels\n",
    "pairs, labels = create_pairs(X, y)\n",
    "\n",
    "# Split into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pairs_train, pairs_val, labels_train, labels_val = train_test_split(pairs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape pairs for model input\n",
    "input_a_train = np.array([pair[0] for pair in pairs_train])\n",
    "input_b_train = np.array([pair[1] for pair in pairs_train])\n",
    "input_a_val = np.array([pair[0] for pair in pairs_val])\n",
    "input_b_val = np.array([pair[1] for pair in pairs_val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "siamese_model.fit([input_a_train, input_b_train], labels_train, \n",
    "                  validation_data=([input_a_val, input_b_val], labels_val),\n",
    "                  epochs=10, \n",
    "                  batch_size=32)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = siamese_model.evaluate([input_a_val, input_b_val], labels_val)\n",
    "print(f'Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.save('siamese_model.h5')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import librosa  \n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "model = load_model('siamese_model.h5')\n",
    "\n",
    "\n",
    "def audio_to_spectrogram(audio_file, output_dir='spectrograms/temp'):\n",
    "  \n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    \n",
    "  \n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "    \n",
    "    \n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    spectrogram_path = os.path.join(output_dir, 'temp_spectrogram.png')\n",
    "    librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel', fmax=8000)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.savefig(spectrogram_path)\n",
    "    plt.close()\n",
    "    \n",
    "    return spectrogram_path\n",
    "\n",
    "\n",
    "def prepare_spectrogram_for_prediction(spectrogram_path):\n",
    "    img = cv2.imread(spectrogram_path)\n",
    "    img = cv2.resize(img, (128, 128))  # Resize to the model input size\n",
    "    img = img.astype('float32') / 255.0  # Normalize to [0, 1]\n",
    "    return img\n",
    "\n",
    "\n",
    "def predict_keyword(audio_file):\n",
    "   \n",
    "    spectrogram_path = audio_to_spectrogram(audio_file)\n",
    "\n",
    "    # Step 2: Prepare the spectrogram for prediction\n",
    "    spectrogram_img = prepare_spectrogram_for_prediction(spectrogram_path)\n",
    "\n",
    "    # Create pairs for prediction (using a reference spectrogram from the training set)\n",
    "    # Load a reference spectrogram for 'bed' and 'happy'\n",
    "    bed_reference = cv2.imread('spectrograms/1_bed.png') \n",
    "    happy_reference = cv2.imread('spectrograms/1_happy/.png')  \n",
    "    \n",
    "    bed_reference = prepare_spectrogram_for_prediction(bed_reference)\n",
    "    happy_reference = prepare_spectrogram_for_prediction(happy_reference)\n",
    "\n",
    "   \n",
    "    input_a = np.expand_dims(spectrogram_img, axis=0)\n",
    "    input_b_bed = np.expand_dims(bed_reference, axis=0)\n",
    "    input_b_happy = np.expand_dims(happy_reference, axis=0)\n",
    "\n",
    "\n",
    "    score_bed = model.predict([input_a, input_b_bed])\n",
    "    score_happy = model.predict([input_a, input_b_happy])\n",
    "\n",
    "\n",
    "    if score_bed > 0.5:\n",
    "        print(\"The audio contains 'bed'. Similarity Score:\", score_bed[0][0])\n",
    "    else:\n",
    "        print(\"The audio does not contain 'bed'. Similarity Score:\", score_bed[0][0])\n",
    "\n",
    "    if score_happy > 0.5:\n",
    "        print(\"The audio contains 'happy'. Similarity Score:\", score_happy[0][0])\n",
    "    else:\n",
    "        print(\"The audio does not contain 'happy'. Similarity Score:\", score_happy[0][0])\n",
    "\n",
    "\n",
    "audio_file = ''  \n",
    "predict_keyword(audio_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
